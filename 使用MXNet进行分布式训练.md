# 使用MXNet进行分布式训练

MXNet支持分布式训练，使我们能够利用多台机器进行更快速的训练。 在本文中，我们描述它是如何工作的，如何启动分布式训练工作和一些提供更多控制的环境变量。

##  并行类型

我们可以通过两种方式来将训练神经网络的工作量分配在多个设备（可以是GPU或CPU）。 第一种方式是数据并行，指的是每个设备存储完整模型副本的情况。 每个设备使用数据集的不同部分进行工作，设备共同更新共享模型。 这些设备可以位于一台机器上，也可以位于多台机器上。 在本文中，我们将描述如何以数据并行方式训练一个模型，其中设备分布在多台机器上。
当模型太大以至于不能适配设备内存时，第二种称为模型并行的方法就很有用。 在这里，不同的设备被分配了学习模型不同部分的任务。 目前，MXNet仅支持单机中的模型并行。 有关这方面的更多信息，请参考[使用模型并行的多GPU的培训](https://mxnet.incubator.apache.org/versions/master/faq/model_parallel_lstm.html)。

## 如何进行分布式训练

接下来的几个概念是理解使用MXNet进行分布式训练的关键：

### 进程的类型

MXNet中有三种进程类型，这些进程之间相互通信，完成模型的训练。

* Worker：Worker节点实际上在一批训练样本上进行训练。 在处理每个批次之前，Workers从服务器上拉出权重。 Worker还会在每批次处理后向服务器发送梯度(gradient)。 根据训练模型的工作量，在同一台机器上运行多个工作进程可能不是一个好主意。

* Server：可以有多个Servers存储模型的参数，并与Workers进行交流。 Serverd可能与工作进程同处一处,也可能不。

* Scheduler(调度器)：只有一个Scheduler。Scheduler的作用是配置集群。这包括等待每个节点启动以及节点正在监听哪个端口之类的消息。 然后Scheduler让所有进程知道集群中的其他节点的信息，以便它们可以相互通信。

``` python
import mxnet
```
